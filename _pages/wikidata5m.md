---
layout: default
permalink: wikidata5m
title: Wikidata5m
image: /assets/images/wikidata5m.jpg
papers:
  - title: "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation"
    authors: [Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juanzi Li, Jian Tang]
    links:
      arXiv: https://arxiv.org/pdf/1911.06136.pdf
      BibTeX: /bibtex/kepler.txt
---

Info
--------
Wikidata5m is a large-scale knowledge graph dataset with aligned text descriptions.

| Statistics |            |
|------------|------------|
| #Entity    | 4,818,298  |
| #Relation  | 822        |
| #Train     | 21,343,681 |
| #Valid     | 5,357      |
| #Test      | 5,321      |

Data
----
- [Knowledge graph], xx GB
- [Text descriptions], xx GB
- [Entity and relation aliases], xx GB

[knowledge graph]: xxx
[text descriptions]: xxx
[Entity and relation aliases]: xxx

Publications
------------
{% include publication papers=page.papers %}